{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "Several years ago, a work friend encouraged me to read the entire Bible from cover to cover. Even though I was well into my thirties and was raised in a Christian home, I'd never done this. There were times I tried, but I usually sputter out around Exodus or Leviticus.\n",
    "\n",
    "But John was so excited about the Bible that every day he would walk through the door and say something like, \"I just read Judges. It was amazing!\" As time went by, he continued to share his progress and excitement, and my desire to read the Bible grew. One day I took the plunge and I have been reading every since.\n",
    "\n",
    "Years later, I've read or listening to the entire Bible every year except one.  It is the most exciting book I've ever read, and I would love to inspire others to take the same plunge. To do this, I'm going to start with some basic analytics and then dig deeper into everything I can think of. I hope something I share will spark the same desire in others.\n",
    "\n",
    "I will use the World English Bible translation as my data source. I have a limited number of translations to choose from and I want to do text analytics using every day English. I downloaded the text from Kaggle. You can find it here: https://www.kaggle.com/oswinrh/bible#t_asv.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up\n",
    "Importing the necessary packages for this study, setting up my project folder as the directory for easier navigation, removing row and column display limits, and telling Jupyter to display all of the output from each cell, not just the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import spacy\n",
    "\n",
    "# Set project folder as directory\n",
    "os.chdir(r'C:/Users/david/Projects/Bible Analytics')\n",
    "\n",
    "# Remove row and column limits\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Display all output from each cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting counts\n",
    "\n",
    "One of the most basic analytics we can do with the Bible text is a counts analysis. In this next section, I will pull the data from our SQL database, tokenize the text using spaCy, and count the number of non-punctuation tokens in each verse. I will then use these counts to generate some basic insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the data from our SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = 'Data/SQL database.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(database)\n",
    " \n",
    "df = pd.read_sql_query('SELECT * FROM t_web', conn)\n",
    " \n",
    "conn.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "\n",
    "Now that I've pulled the data, I'm going to process it using spaCy. I'll wrap the code in a FOR loop so that I can process each row of data using the same approach. \n",
    "\n",
    "In the first line of code I define a language object called nlp. When defining nlp, I will load a small, English language, trained pipe line called \"en_core_web_sm\". I only need this object to tokenize (split the text into individual words, numbers, punctuations, etc.) the data so that I can get a word count for each verse. As such, I won't load anything bigger than this. \n",
    "\n",
    "Next, I create an empty list into which the word count for each row of text can be inserted. I'll name this word_count. I'm also going to time this process, so we can see how quickly this happens. Feel free to ignore the *datatime, start, stop* stuff. \n",
    "\n",
    "After this, I use a FOR loop to iterate through the rows of data. This code is pretty typical and you can find tons of resources with more detail about iterating through dataframes. Within the FOR loop, I'm defining \"doc\" by applying our nlp object to each row of text data. Then, I'm creating a variable called \"count\" and setting it's initial value to zero. For each row, count will reset to zero before the text data is processed. Once this is done, I'm creating a nested FOR loop which will iterate through every token in our doc object. I'm not interested in punctuation, so I use an IF statement to tell the code to ignore punctuation tokens. Then I increase the count variable by 1 for each non-punctuation token. This continues until all non-punctuation tokens have been accounted for. Once this happens, the nested FOR loop will end and the final count for that row of data will be appended to our predefined list, word_count. This continues until all of rows of data have been analyzed. The last thing I'll do before analyzing this data is insert all of the word counts into our dataframe.\n",
    "\n",
    "Shew... take a breath. We're done with the technical stuff for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "word_count = []\n",
    "\n",
    "# Ignore this\n",
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "# Stop ignoring\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    doc = nlp(row['clean_t'])\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token.is_punct:\n",
    "            \n",
    "            count+=1\n",
    "            \n",
    "    word_count.append(count)\n",
    "    \n",
    "df['word_count'] = pd.Series(word_count)\n",
    "\n",
    "# Ignore this\n",
    "stop = datetime.now()\n",
    "\n",
    "print('This process took', stop-start)\n",
    "print()\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! If I were to physically count each word in the Bible, it would take months and there would be a high likelihood of mistakes. Thanks to technology, I'm able to accomplish the same task in just over three minutes with no chance of mistakes... as long as I got everything right. \n",
    "\n",
    "Looking at the first five rows of our data, the counts appear to be in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let the analysis begin!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = len(df['b'].unique())\n",
    "chapters = len(df[['b', 'c']].drop_duplicates())\n",
    "verses = len(df[['b', 'c', 'v']].drop_duplicates())\n",
    "words = df['word_count'].sum()\n",
    "\n",
    "print('There are {} books in the Bible, {} chapters in those books, {} verses in those chapters, and {} words in those verses.'.format(books, chapters, verses, words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of books and chapters shouldn't change from one translation to the next, but we already know the number of verses will be lower in this particular translation and the number of words will almost certainly be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the shortest verse in the Bible?\n",
    "\n",
    "Notice, that I filtered to verses whose count exceeds 0. In this translation, some verses have no words because the translating team determined that those verses where not in the earliest manuscripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['word_count']>0][['name', 'c', 'v', 'clean_t', 'word_count']].sort_values(['word_count']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a three-way tie. There is the classic John 11:35 - \"Jesus wept\", there is also 1 Thessalonians 5:16 - \"Rejoice always\", and my new favorite, Job 3:2 - \"Job answered.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the longest books in the Bible? Shortest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[['name', 'word_count']].groupby(['name'])['word_count'].sum()\n",
    "\n",
    "book_count = pd.DataFrame(temp).sort_values(['word_count'], ascending=False).reset_index()\n",
    "\n",
    "book_count.head()\n",
    "book_count.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, Jeremiah is the longest book in this translation of the Bible. Then Psalms, Ezekiel, Genesis and Isaiah. 3 John is the shortest, followed by 2 John, Philemon, Jude and Obadiah."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How long does it take to read the Bible?\n",
    "According to scholarwithin.com, the average adult can silently read 238 words per minute and read aloud 183.\n",
    "\n",
    "https://scholarwithin.com/average-reading-speed#:~:text=Adult%20Average%20Reading%20Speed,-It%20has%20been&text=Silent%20reading%20adults%20average%20238,average%20183%20words%20per%20minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes = 769817/238\n",
    "hour_days = minutes/60\n",
    "half_hour_days = minutes/30\n",
    "quarter_hour_days = minutes/15\n",
    "ten_minute_days = minutes/10\n",
    "in_a_year = minutes/365\n",
    "\n",
    "round(hour_days)\n",
    "round(half_hour_days)\n",
    "round(quarter_hour_days)\n",
    "round(ten_minute_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What it takes\n",
    "Based on the average number of words an adult can silently read per minute, it would take most adults 54 hours to silently read the entire Bible. That's 108 days if you read for half an hour per day, 216 days if you read for fifteen minutes per day, and 323 days if you read for ten minutes. So, the average adult can read the entire Bible in just under a year by silently reading for around 10 minutes per day. \n",
    "\n",
    "Of course, this requires a ton of discipline, which means some people will be better at this approach than others. Personally, I've never had much luck setting aside ten minutes a day to read. I either read for way longer or completely miss a day, then two, then a week... well, you get the point. Some of us are just better at this than others.\n",
    "\n",
    "So what about the rest of us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You could always listening to the audio Bible\n",
    "Most of the time, I use the audio function on my phone to listen to the Bible while taking a morning walk. This seems to work best for me. So, the question is, how long does it take to listen to the entire Bible? \n",
    "\n",
    "According to scholarwithin.com, the average person can read aloud 183 words per minutes. I will assuming this is a good estimate for the person reading my preferred translation of the Bible. However, before jumping straight into the calculations, we should acknowledge a couple other factors that may interfere:\n",
    "1. My reader starts each book and chapter with a short intro. This may not seem like much, but remember there are 66 books in the Bible and 1,189 chapters. This adds up. \n",
    "2. Sometimes, I want to listen to a passage again for clarification or because I've never thought about before.\n",
    "\n",
    "We can't do anything about the second factor, but we can adjust for the first. My reader says around ten words to introduce each book and something like, \"Genesis chapter one\" before reading each chapter. That's ten additional words for each book and three additional words per chapter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3*1189 + 10*66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes = (769817 + 4227)/183\n",
    "\n",
    "# Listening for 30 minutes each weekday\n",
    "days1 = minutes/30\n",
    "weeks1 = days/5\n",
    "\n",
    "# Listening for 15 minutes every day\n",
    "days2 = minutes/15\n",
    "weeks2 = days2/7\n",
    "\n",
    "# Listening for 20 minutes each weekday\n",
    "days3 = minutes/20\n",
    "weeks3 = days3/5\n",
    "\n",
    "print('You could listen to the entire Bible in', \n",
    "      round(weeks1), 'weeks if you listened for thirty minutes each weekday,', \n",
    "      round(weeks2), 'weeks if you listened for 15 minutes every single day, and',\n",
    "      round(weeks3), 'weeks if you listened for 20 minutes each weekday.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What it takes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I usually go for a half hour walk in the mornings, so based on the above calculations it would take 28 weeks to listen to the entire Bible during my walks, assume I never miss a day and I only do this on weekdays. I could listen to the entire Bible in around 28 weeks, At this rate, if I start listening to Genesis on January 1st, I would finish Revelations halfway through July."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other possibilities\n",
    "\n",
    "Here's another possibilities. We each take daily showers... ish. Well, let's just assume we do. And let's say this basic standard of hygiene takes fifteen minutes a day. If you have a shower speaker, you could listen to the entire Bible in 40 weeks. \n",
    "\n",
    "Perhaps, you still drive to work each morning. Let's assume an average of 20 minutes and that you work five days a week. You could have the Bible finished in 42 weeks by listening on the drive to work, or in half that time by listening both ways.\n",
    "\n",
    "There's also time doing daily chores; washing dishes, doing laundry, cleaning the living room. These are fairly mindless tasks and with the technology we have today, you no longer have to focus all of your attention on reading the Bible. You can pop in some ear buds and work away. \n",
    "\n",
    "I know this may not be a simple as it sounds. Depending on where you are in life, you may have a toddler who won't allow you to properly use the bathroom without barging in or a new born who cries while you're folding clothes. There are those among us whose every free moment is spoken for, and I get that. There are also those among us who feel like listening to some old man read through the Bible is just the worst. If so, you should check out the Streetlights app. It's pretty amazing!\n",
    "\n",
    "The point is, for most of us there are many opportunities to listen to God's word every day, without setting aside ten minutes each morning to reading without distraction. I hope reading this will inspire you to think about the possibilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
